<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	@font-face {
		font-family: VenusCarrare;
		src: url("fonts/Venus+Carrare.otf");
	}

	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}

	p {
		text-align: justify;
	}
	
	h1 {
		font-family: VenusCarrare;
		font-size:32px;
		font-weight:300;
	}
	
	.paperTitle {
		font-family: VenusCarrare;
		font-size: 36px;
		font-weight: 300;
		display: inline-block;
		/* padding-bottom: 25px; */
	}

	.disclaimerbox {
		background-color: #eee;		
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}
	
	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}
	
	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		15px 15px 0 0px #fff, /* The fourth layer */
		15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		20px 20px 0 0px #fff, /* The fifth layer */
		20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		25px 25px 0 0px #fff, /* The fifth layer */
		25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
		margin-bottom: 25px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}
	
	.vert-cent {
		position: relative;
		top: 50%;
		transform: translateY(-50%);
	}
	
	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}

	/* Vertical alignment for author list: */
	.author{
		vertical-align: top;
	}

	/* .bibBox {
		width: 320px;
		padding: 10px;
		border: 5px dashed rgb(214, 214, 214);
		margin: 0;
	} */
	.bibBox {
    width: 600px;
    padding: 10px;
    border: 5px dashed rgb(214, 214, 214);
    margin: 0;
    font-family: monospace; /* To maintain the monospace appearance */
    white-space: pre-line; /* To retain the whitespace and line breaks */
	background-color: #c0d3e64a;
}

</style>

<html>
<head>
	<title>Explorable Mesh Deformation Subspaces from Unstructured Generative Models</title>
	<meta property="og:image" content="https://armanmaesumi.github.io/explorable_subspaces/resources/paper_teaser.png"/> <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/ if you update and want to force Facebook to rescrape. -->
	<meta property="og:title" content="Explorable Mesh Deformation Subspaces from Unstructured Generative Models" />
	<meta property="og:description" content="A. Maesumi In SIGGRAPH Asia 2023." />

	<!-- Get from Google Analytics -->
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src=""></script> 
	<!-- <script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'UA-75863369-6');
	</script> -->
</head>

<body>
	<br>
	<center>
		<span class="paperTitle">Explorable Mesh Deformation Subspaces from Unstructured Generative Models</span>
		<h1 style="font-size: 22px;">SIGGRAPH Asia 2023</h1>
		<table align=center width=800px>
			<table align=center width=800px>
				<tr>
					<td align=center width=100px class="author">
						<center>
							<span style="font-size:24px"><a href="https://armanmaesumi.github.io/">Arman Maesumi</a></span>
							<br>
							Brown University
						</center>
					</td>
					<td align=center width=100px class="author">
						<center>
							<span style="font-size:24px"><a href="https://paulguerrero.net/">Paul Guerrero</a></span>
							<br>
							Adobe Research
						</center>
					</td>
					<td align=center width=100px class="author">
						<center>
							<span style="font-size:24px"><a href="http://www.vovakim.com/">Vladimir G. Kim</a></span>
							<br>
							Adobe Research
						</center>
					</td>
					<td align=center width=100px class="author">
						<center>
							<span style="font-size:24px"><a href="https://techmatt.github.io/">Matthew Fisher</a></span>
							<br>
							Adobe Research
						</center>
					</td>
					<td align=center width=100px class="author">
						<center>
							<span style="font-size:24px"><a href="https://www.cse.iitb.ac.in/~sidch/">Siddhartha Chaudhuri</a></span>
							<br>
							Adobe 
							<br>
							Research
						</center>
					</td>
					<td align=center width=100px class="author">
						<center>
							<span style="font-size:24px"><a href="https://noamaig.github.io/">Noam Aigerman</a></span>
							<br>
							University of Montreal,
							Adobe Research
						</center>
					</td>
					<td align=center width=100px class="author">
						<center>
							<span style="font-size:24px"><a href="https://dritchie.github.io/">Daniel Ritchie</a></span>
							<br>
							Brown University
						</center>
					</td>
				</tr>
			</table>
			<table align=center width=250px>
				<tr>
					<td align=center width=120px>
						<center>
							<span style="font-size:24px; margin: 10px;"><a href='https://armanmaesumi.github.io/papers/2023_explorable_subspaces/explorable_subspaces.pdf'>[Paper]</a></span>
						</center>
					</td>
					<td align=center width=120px>
						<center>
							<span style="font-size:24px; margin: 10px;"><a href='https://github.com/ArmanMaesumi/generative-mesh-subspaces'>[GitHub]</a></span><br>
						</center>
					</td>
					<td align=center width=120px>
						<center>
							<span style="font-size:24px; margin: 10px;"><a href='./resources/bibtex.txt' target="_blank">[Bibtex]</a></span><br>
						</center>
					</td>
				</tr>
			</table>
		</table>
	</center>

	<!-- TEASER -->
	<center>
		<table align=center width=850px>
			<tr>
				<td width=260px>
					<center>
						<img class="round" style="width:850px;margin:30px" src="./resources/paper_teaser.png"/>
					</center>
				</td>
			</tr>
		</table>
		<table align=center width=850px>
			<tr>
				<td>
					<p>
						<b>Figure 1.</b> We present a method to explore variations among a given set of input shapes (denoted by black Voronoi centers on the left) using a two-dimensional exploration space. This exploration space smoothly and naturally interpolates between the input shapes by constructing a mapping to a sub-space of a pre-trained generator's latent space that optimizes the smoothness of interpolations along any trajectory. Additionally, we transfer the variation over these interpolation trajectories onto the original high-quality meshes, avoiding loss of detail from the unstructured generator output.
					</p>
				</td>
			</tr>
		</table>
	</center>

	<hr>

	<!-- ABSTRACT -->
	<table align=center width=850px>
		<center><h1>Abstract</h1></center>
		<tr>
			<td>
				<p>
					Exploring variations of 3D shapes is a time-consuming process in traditional 3D modeling tools. Deep generative models of 3D shapes often feature continuous latent spaces that can, in principle, be used to explore potential variations starting from a set of input shapes; in practice, doing so can be problematic&mdash;latent spaces are high dimensional and hard to visualize, contain shapes that are not relevant to the input shapes, and linear paths through them often lead to sub-optimal shape transitions. Furthermore, one would ideally be able to explore variations in the original high-quality meshes used to train the generative model, not its lower-quality output geometry. In this paper, we present a method to explore variations among a given set of <i>landmark</i> shapes by constructing a mapping from an easily-navigable 2D exploration space to a subspace of a pre-trained generative model.
					We first describe how to find a mapping that spans the set of input landmark shapes and exhibits smooth variations between them. We then show how to turn the variations in this subspace into deformation fields, to transfer those variations to high-quality meshes for the landmark shapes. Our results show that our method can produce visually-pleasing and easily-navigable 2D exploration spaces for several different shape categories, especially as compared to prior work on learning deformation spaces for 3D shapes.
				</p>
			</td>
		</tr>
	</table>
	<br>

	<hr>

	<center><h1>Method</h1></center>

	<table align=center width=850px>
		<center>
			<tr>
				<td>
					<p>
					Our method creates a two-dimensional exploration space that smoothly interpolates between a set of input shapes. We first find a mapping from the input shapes to a subspace of a pre-trained generative model. We then optimize the mapping to ensure that interpolations between the input shapes are smooth. Finally, we transfer the variations in the exploration space to the original high-quality meshes.
					</p>
				</td>
			</tr>
		</center>
	</table>

	<table align=center width=450px>
		<tr>
			<td align=center width=400px>
				<center>
					<td><img class="round" style="width:450px;margin: 10px;" src="./resources/fig_linearVsGeodesic.png"/></td>
				</center>
			</td>
		</tr>
	</table>

	<table align=center width=850px>
		<center>
			<tr>
				<td>
					<p>
					Resolving such a mapping is non-trivial. As seen in the figure above, linearly interpolating in the latent space of generative models results in undesirable behavior. When interpolating, we need to account for the <i>metric</i> induced by the generator&mdash;in one-dimensional interpolation this corresponds to finding a geodesic path connecting source and target points on the shape manifold. However, in our setting we seek a two dimensional <b>surface</b> that is immersed in the shape manifold, such that interpolants along the surface are as geodesic as possible.
					</p>
				</td>
			</tr>
		</center>
	</table>

	<table align=center width=850px>
		<tr>
			<td align=center width=400px>
				<center>
					<td><img class="round" style="width:850px" src="./resources/paper_pipeline.png"/></td>
				</center>
			</td>
		</tr>
	</table>
	<br>
	<table align=center width=850px>
		<center>
			<!-- <tr>
				<td>
					<p>
					Our learned mapping reparametrizes the domain of the generator such that its <i>image</i> is "as geodesic as possible" with respect to the curvature induced by the generator. Interpolating through our mapping results in smoother transitions between shapes.
					</p>
				</td>
			</tr> -->
			<tr>
				<td width=250px>
					<p>
						Our learned mapping smoothly interpolates the landmark shapes by reparametrizing the domain of the generator such that its <i>image</i> is "as geodesic as possible" with respect to the curvature induced by the generator. We formulate a constrained optimization objective that ensures the landmark shapes are always mapped correctly and that the embedding minimizes an energy accounting for the metric of the shape manifold&mdash;the Dirichlet energy. The resulting surface given by our map can be thought of as a "smooth membrane" spanning a subset of the shape manifold. Interpolating between shapes along this membrane results in smoother transitions between shapes.
					</p>
				</td>
				<td width="25px"></td>
				<td width="400px">
					<center>
						<img class="round" style="width:400px;" src="./resources/fig_oursVsBary.png"/>
					</center>
					<br>
					<p>
						<b>Figure 6.</b> Visualization of the log-energy of our mapping. Naively lifting exploration spaces into the primal domain (e.g. by barycentrically interpolating landmark latents) results in noisy interpolants. Our method incurs far less energy overall, which primarily occurs on the facet boundaries.	
					</p>
				</td>
			</tr>
		</center>
	</table>
	<br>
	<table align=center width=450px>
		<tr>
			<td align=center width=400px>
				<center>
					<td><img class="round" style="width:450px;margin: 10px;" src="./resources/fig_InterpDeform.png"/></td>
				</center>
			</td>
		</tr>
	</table>

	<table align=center width=850px>
		<center>
			<tr>
				<td>
					<p>
					Finally, we transfer the variations of the the unstructured (point cloud) shapes onto the original high-quality meshes. To do this, we interpret an interpolation through our 2D exploration space as a flow on the meshes's vertices. 
					</p>
				</td>
			</tr>
		</center>
	</table>

	<hr>

	<center><h1>Results</h1></center>

	<table align=center width=850px>
		<center>
			<tr>
				<td>
					<p>
					We demonstrate results on shape-to-shape deformation tasks, as well as free-form deformation and shape space exploration (refer to supplementary video below).
					</p>
				</td>
			</tr>
		</center>
	</table>

	<table align=center width=450px>
		<tr>
			<td align=center width=400px>
				<center>
					<td><img class="round" style="width:850px;margin: 10px;" src="./resources/fig_shapeToShape.png"/></td>
				</center>
			</td>
		</tr>
	</table>
	<table align=center width=850px>
		<tr>
			<td>
				<p>
					<b>Figure 9.</b> Additional shape-to-shape deformation results from our airplane and table exploration spaces. Our method is able to capture complex deformations; for instance, in column four we see the airliner's wings bending forward to match the straight wing's of the propeller plane. Additionally, in the last column we see that our method is able to locally deform the table top while maintaining the geometry elsewhere.
				</p>	
			</td>
		</tr>
	</table>

	<table align=center width=450px>
		<tr>
			<td align=center width=400px>
				<center>
					<td><img class="round" style="width:850px;margin: 10px;" src="./resources/fig_shapeFlowComparison.png"/></td>
				</center>
			</td>
		</tr>
	</table>
	<table align=center width=850px>
		<tr>
			<td>
				<p>
					<b>Figure 8.</b> We demonstrate our shape-to-shape deformation results against ShapeFlow, whereby we take random source and target meshes, and deform between them continuously. We visualize the final deformed shapes (at t=1) as well as the source and target meshes. We can see that our method exhibits deformations that better preserve the fine details of the original shapes, while matching the structure of the target shapes more closely compared to ShapeFlow.
				</p>	
			</td>
		</tr>
	</table>
	<br>
	<hr>

	<table align=center width=450px>
		<center><h1>Media</h1></center>
		<tr>
			<td>
				Supplementary video:
			</td>
		</tr>
		<tr>
			<td align=center width=400px>
				<center>
					<video width=850 style="border: 1px solid black;" controls>
						<source src="./resources/supp_video.mp4" type="video/mp4">
					</video>
				</center>
			</td>
		</tr>
	</table>

	<hr>
	<table align=center width=500px>
		<center><h1>Paper and Supplementary Material</h1></center>
		<tr>
			<td><a href=""><img class="layered-paper-big" style="height:175px" src="./resources/paper.png"/></a></td>
			<td><span style="font-size:14pt">A. Maesumi, P. Guerrero, V. Kim, M. Fisher, S. Chaudhuri, N. Aigerman, D. Ritchie<br>
				<b>Explorable Mesh Deformation Subspaces from Unstructured Generative Models.</b><br>
				In SIGGRAPH Asia, 2023.<br>
				(coming soon)<br>
				<span style="font-size:4pt"><a href=""><br></a>
				</span>
			</td>
		</tr>
	</table>
	
	<br>

	<table align=center width=600px>
		<tr>
			<td>
				Bibtex:
				<div class="bibBox">@article{maesumi2023explore,
						author = {Maesumi, Arman and Guerrero, Paul and Kim, Vladimir G. and Fisher, Matthew and Chaudhuri, Siddhartha and Aigerman, Noam and Ritchie, Daniel},
						title = {Explorable Mesh Deformation Subspaces from Unstructured Generative Models},
						year = {2023},
						booktitle = {ACM SIGGRAPH Asia 2023 Conference Proceedings},
						publisher = {Association for Computing Machinery},
						doi = {10.1145/3610548.3618192},
					}
				</div>
			</td>
		</tr>
	</table>

	<hr>

	<table align=center width=900px>
		<tr>
			<td width=400px>
				<left>
					<center><h1>Acknowledgements</h1></center>
					This material is based upon work supported by the National Science Foundation Graduate Research Fellowship under Grant No. 2040433.
					
					This <a href="https://github.com/richzhang/webpage-template">project page template</a> was originally made by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> and <a href="http://richzhang.github.io/">Richard Zhang</a>.
				</left>
			</td>
		</tr>
	</table>

<br>
</body>
</html>

