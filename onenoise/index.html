<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	@font-face {
		font-family: VenusCarrare;
		src: url("fonts/Venus+Carrare.otf");
	}

	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}

	p {
		text-align: justify;
	}
	
	h1 {
		font-family: VenusCarrare;
		font-size:32px;
		font-weight:300;
	}
	
	.paperTitle {
		font-family: VenusCarrare;
		font-size: 36px;
		font-weight: 300;
		display: inline-block;
		/* padding-bottom: 25px; */
	}

	.disclaimerbox {
		background-color: #eee;		
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}
	
	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}
	
	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		15px 15px 0 0px #fff, /* The fourth layer */
		15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		20px 20px 0 0px #fff, /* The fifth layer */
		20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		25px 25px 0 0px #fff, /* The fifth layer */
		25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
		margin-bottom: 25px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}
	
	.vert-cent {
		position: relative;
		top: 50%;
		transform: translateY(-50%);
	}
	
	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}

	/* Vertical alignment for author list: */
	.author{
		vertical-align: top;
	}

	/* .bibBox {
		width: 320px;
		padding: 10px;
		border: 5px dashed rgb(214, 214, 214);
		margin: 0;
	} */
	.bibBox {
    width: 600px;
    padding: 10px;
    border: 5px dashed rgb(214, 214, 214);
    margin: 0;
    font-family: monospace; /* To maintain the monospace appearance */
    white-space: pre-line; /* To retain the whitespace and line breaks */
	background-color: #c0d3e64a;
}

</style>

<html>
<head>
	<title>One Noise to Rule Them All: Learning a Unified Model of Spatially-Varying Noise Patterns</title>
	<meta property="og:image" content="https://armanmaesumi.github.io/onenoise/resources/paper_teaser.png"/> 
	<meta property="og:title" content="One Noise to Rule Them All: Learning a Unified Model of Spatially-Varying Noise Patterns" />
	<meta property="og:description" content="A. Maesumi In SIGGRAPH 2024." />

	<!-- Get from Google Analytics -->
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src=""></script> 
	<!-- <script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'UA-75863369-6');
	</script> -->
</head>

<body>
	<br>
	<center>
		<span class="paperTitle">One Noise to Rule Them All:<br>Learning a Unified Model of Spatially-Varying Noise Patterns</span>
		<h1 style="font-size: 22px;">Transactions on Graphics (Proceedings of SIGGRAPH 2024)</h1>
		<table align=center width=800px>
			<table align=center width=800px>
				<tr>
					<td align=center width=100px class="author">
						<center>
							<span style="font-size:24px"><a href="https://armanmaesumi.github.io/">Arman Maesumi</a></span>
							<br>
							Brown University
						</center>
					</td>
					<td align=center width=100px class="author">
						<center>
							<span style="font-size:24px"><a href="https://dylan.hu/">Dylan<br>Hu</a></span>
							<br>
							Brown University
						</center>
					</td>
                    <td align=center width=100px class="author">
						<center>
							<span style="font-size:24px"><a href="">Krishi<br>Saripalli</a></span>
							<br>
							Brown University
						</center>
					</td>
					<td align=center width=100px class="author">
						<center>
							<span style="font-size:24px"><a href="http://www.vovakim.com/">Vladimir G. Kim</a></span>
							<br>
							Adobe Research
						</center>
					</td>
					<td align=center width=100px class="author">
						<center>
							<span style="font-size:24px"><a href="https://techmatt.github.io/">Matthew Fisher</a></span>
							<br>
							Adobe Research
						</center>
					</td>
					<td align=center width=100px class="author">
						<center>
							<span style="font-size:24px"><a href="https://storage.googleapis.com/pirk.io/index.html">S&ouml;ren Pirk</a></span>
							<br>
                            CAU
						</center>
					</td>
					<td align=center width=100px class="author">
						<center>
							<span style="font-size:24px"><a href="https://dritchie.github.io/">Daniel Ritchie</a></span>
							<br>
							Brown University
						</center>
					</td>
				</tr>
			</table>
			<br>
			<table align=center width=600px>
				<tr>
					<div style="display: flex; justify-content: space-between; width: 600px; align-items: center;">
						<span style="display: flex; font-size: 22px; text-align: center;">
							<a href='https://armanmaesumi.github.io/papers/2024_onenoise/sigg24_onenoise.pdf'>[Paper, 34mb]</a>
						</span>
						<span style="display: flex; font-size: 22px; text-align: center;">
							<a href='https://armanmaesumi.github.io/papers/2024_onenoise/sigg24_onenoise_supplemental.pdf'>[Supp., 12mb]</a>
						</span>
						<!-- <span style="display: flex; font-size: 22px; text-align: center;">
							<a href=''>[arXiv]</a>
						</span>
						<span style="display: flex; font-size: 22px; text-align: center;">
							<a href=''>[GitHub]</a>
						</span> -->
						<span style="display: flex; font-size: 22px; text-align: center;">
							<a href='./resources/bibtex.txt' target="_blank">[Bibtex]</a>
						</span>
					</div>
					
					<br> arXiv and GitHub coming soon!
				</tr>
			</table>
		</table>
	</center>

	<br>

	<!-- TEASER -->
	<center>
		<table align=center width=850px>
			<tr>
				<td width=260px>
					<center>
                        <!-- use magnifying glass effect -->
                        <!-- <div class="img-magnifier-container"> -->
                        <img id="paper_teaser" src="./resources/paper_teaser.jpg" width="850px" style="border-radius: 3px">
                        <!-- </div> -->
						<!-- <img class="round" style="width:850px;margin:30px" src="./resources/paper_teaser.jpg"/> -->
					</center>
				</td>
			</tr>
		</table>
		<!-- <table align=center width=850px>
			<tr>
				<td>
					<p>
						<b>Figure 1.</b> Our method enables the synthesis of a wide range of noise patterns with spatially-varying characteristics. Here we show the flexibility of our unified noise model, allowing one to art-direct their noise in a granular fashion. Our model creates semantically meaningful interpolations between noise configurations; above we see the Siggraph logo written with <span style="font-family: monospace;">hay fibers</span> that are nested inside of <span style="font-family: monospace;">Damascus steel</span> striations -- the scale and distortion of the steel pattern naturally interpolates into a denser pattern before transitioning into fibers. We also show renderings of a clay shader that incorporates our spatially-varying noise patterns. The first three images make use of class-interpolated noise, the final image uses parameter-interpolated noise. Please zoom into the figures for full visual detail.
					</p>
				</td>
			</tr>
		</table> -->
	</center>
	<!-- <hr> -->
	<!-- ABSTRACT -->
	<table align=center width=850px>
		<center><h1>Abstract</h1></center>
		<tr>
			<td>
				<p>
                    Procedural noise is a fundamental component of computer graphics pipelines, offering a flexible way to generate textures that exhibit "natural" random variation. Many different types of noise exist, each produced by a separate algorithm. In this paper, we present a single generative model which can learn to generate multiple types of noise as well as blend between them. In addition, it is capable of producing spatially-varying noise blends despite not having access to such data for training. These features are enabled by training a denoising diffusion model using a novel combination of data augmentation and network conditioning techniques. Like procedural noise generators, the model's behavior is controllable via interpretable parameters plus a source of randomness. We use our model to produce a variety of visually compelling noise textures. We also present an application of our model to improving inverse procedural material design; using our model in place of fixed-type noise nodes in a procedural material graph results in higher-fidelity material reconstructions without needing to know the type of noise in advance.
				</p>
			</td>
		</tr>
	</table>
	<br>

	<hr>
	
	<table align=center width=850px>
		<center><h1>High-level Summary</h1></center>
		<tr>
			<td>
				<p>
                    <b>Goal:</b> Learn a denoising diffusion model that can produce multiple types of parametrized noise functions and blend between them spatially.
                    
                    <br><br>

                    <b>Problem:</b> Training a denoising U-Net <b>without</b> spatially-varying noise data results in poor adherence to the conditioning signal.
                    
                    <br><br>
                    
                    <b>Insights:</b>
                    <ol>
                        <li>The U-Net's bottleneck architecture causes a smearing effect on the network's learned features.</li>
                        <br>
                        <li>Spatially-varying synthesis requires the U-Net to denoise along multiple denoising trajectories simultaneously, which is difficult in the absence of spatially-varying noise data.</li>
                      </ol> 
                    <br>

                    <b>Solution:</b> We propose a novel variant of CutMix data augmentation, which creates synthetic training samples that are collage-like amalgamations of multiple noise types. This forces the U-Net to respect the spatially-varying conditioning signal, and improves its ability to denoise along multiple trajectories.
				</p>
			</td>
		</tr>   
	</table>
    <br>
    <table align=center width=850px>
        <tr>
            <td width=260px>
                <center>
                    <img id="paper_teaser" src="./resources/fig_pipeline.jpg" width="850px">
                </center>
            </td>
        </tr>
    </table>
    <table align=center width=850px>
        <tr>
            <td>
                <p>
                    <b>Figure 3.</b> During training, we first transform the current data sample (highlighted in blue) by cutting and patching together a set of other random samples from the dataset, resulting in a training image <b>x<sub>0</sub></b>. The noise parameters for each image patch are passed to an MLP, which projects the parameter sets into an embedding space that encodes both the noise type (class) and the noise parameters. The resulting feature vectors are tiled to form a feature grid, which is used as a conditioning signal in the U-Net's SPADE blocks.
                </p>
            </td>
        </tr>
    </table>

	<br>

    <table align=center width=850px>
        <tr>
            <td width=260px>
                <center>
                    <img id="paper_teaser" src="./resources/fig_inference.jpg" width="850px">
                </center>
            </td>
        </tr>
    </table>
    <table align=center width=850px>
        <tr>
            <td>
                <p>
                    <b>Figure 4.</b> At inference time, we query our network using artificially constructed feature grids, enabling a flexible way to synthesize spatially-varying noise patterns. Here we embed four sets of noise parameters, pictorially shown as one of four colors. We blend the feature vectors using bilinear interpolation, creating a smoothly-varying feature grid, which our U-Net is able to transform into a Voronoi noise pattern with non-uniform scale and distortion characteristics.
                </p>
            </td>
        </tr>
    </table>

    <hr>

    <table align=center width=850px>
		<center><h1>Results</h1></center>
		<tr>
            <td width=260px>
                <center>
                    <img id="paper_teaser" src="./resources/res1.png" width="850px">
                    <br><br>
                    <img id="paper_teaser" src="./resources/res5.png" width="850px" height="200px" style="object-fit: cover;-webkit-transform: scaleX(-1);
                    transform: scaleX(-1);">
                    <br><br>
                    <img id="paper_teaser" src="./resources/res4.png" width="850px" height="200px" style="object-fit: cover;">
                    <br><br>
                    <img id="paper_teaser" src="./resources/res3.png" width="850px" height="200px" style="object-fit: cover;-webkit-transform: scaleX(-1);
                    transform: scaleX(-1);">
                    <br><br>
                    <img id="paper_teaser" src="./resources/res2.png" width="850px" height="200px" style="object-fit: cover;-webkit-transform: scaleX(-1);
                    transform: scaleX(-1);">
                    
                    <br><br>
                    <!-- Create 2x2 grid of images: -->
                    <div style="display: grid; grid-template-columns: repeat(2, 1fr); grid-gap: 10px;">
                        <img id="paper_teaser" src="./resources/grid1.png" width="420px">
                        <img id="paper_teaser" src="./resources/grid2.png" width="420px">
                        <img id="paper_teaser" src="./resources/grid3.png" width="420px">
                        <img id="paper_teaser" src="./resources/grid4.png" width="420px">
                    </div>

                    <br>
                    <img id="paper_teaser" src="./resources/res6.png" width="850px">
                </center>
            </td>
		</tr>   
	</table>
    <br>
    <hr>

    <table align=center width=850px>
		<center><h1>Inverse Procedural Material Design</h1></center>
		<tr>
			<td>
				<p>
                    We demonstrate that our model can be used as a differentiable proxy for noise generator nodes in a procedural material graph. Using our model in place of fixed-type noise nodes results in higher-fidelity material reconstructions.
				</p>
			</td>
		</tr>
	</table>
    <table align=center width=850px>
        <tr>
            <td width=260px>
                <center>
                    <img id="paper_teaser" src="./resources/fig_optimizedNoise.jpg" width="850px">
                </center>
            </td>
        </tr>
    </table>
    <table align=center width=850px>
        <tr>
            <td>
                <p>
                    <b>Figure 7.</b> Given a procedural material graph and a target photograph, our noise generative model serves as a useful prior over the space of noise functions, facilitating the recovery of non-trivial patterns that are present in the target photos, and improving the baseline result given by MATch. Two similarity scores are reported for each result with respect to the target image: MATch's feature-based texture similarity metric (left) and LPIPS (right). Lower is better for both scores.
                </p>
            </td>
        </tr>
    </table>
    <table align=center width=850px>
        <tr>
            <td width=260px>
                <center>
                    <img id="paper_teaser" src="./resources/fig_editGraph.png" width="450px">
                </center>
            </td>
        </tr>
    </table>
    <table align=center width=850px>
        <tr>
            <td>
                <p>
                    <b>Figure 10.</b> After optimization, we can easily modify the resulting procedural material graphs. Here a marble material graph is optimized (first row), and edited in various ways (second row). We show the results of editing the noise colorization, resampling our diffusion noise, and modifying our model's conditioning inputs.
                </p>
            </td>
        </tr>
    </table>
    <br>

    <hr>
	<table align=center width=550px>
		<center><h1>Paper and Supplementary Material</h1></center>
		<tr>
			<td><a href=""><img class="layered-paper-big" style="height:175px" src="./resources/paper.png"/></a></td>
			<td><span style="font-size:14pt">A. Maesumi, D. Hu, K. Saripalli, V. Kim, M. Fisher, S. Pirk, D. Ritchie<br>
				<b>One Noise to Rule Them All:<br>Learning a Unified Model of Spatially-Varying Noise Patterns.</b><br>
				In ACM Transactions on Graphics (Proceedings of SIGGRAPH 2024).<br>
                arXiv: Coming Soon!<br>
			</td>
		</tr>
	</table>
    <br>
	<table align=center width=600px>
		<tr>
			<td>
				Bibtex:
				<div class="bibBox">@article{maesumi2024noise,
						author = {Maesumi, Arman and Hu, Dylan and Saripalli, Krishi and Kim, Vladimir G. and Fisher, Matthew and Pirk, S&ouml;ren and Ritchie, Daniel},
						title = {One Noise to Rule Them All: Learning a Unified Model of Spatially-Varying Noise Patterns},
						year = {2024},
						booktitle = {ACM Transactions on Graphics (Proceedings of SIGGRAPH 2024)},
						publisher = {Association for Computing Machinery}
					}
				</div>
			</td>
		</tr>
	</table>

	<hr>

	<table align=center width=900px>
		<tr>
			<td width=400px>
				<left>
					<center><h1>Acknowledgements</h1></center>
					This material is based upon work that was supported by the National Science Foundation Graduate Research Fellowship under Grant No. 2040433. Part of this work was done while Arman Maesumi was an intern at Adobe Research.
					
					This <a href="https://github.com/richzhang/webpage-template">project page template</a> was originally made by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> and <a href="http://richzhang.github.io/">Richard Zhang</a>.
				</left>
			</td>
		</tr>
	</table>

<br>
</body>

</html>

